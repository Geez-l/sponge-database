{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "sponge_path = r\"D:\\Fourth-Year\\sponge-database\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "date_iso() missing 1 required positional argument: 'df'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(output, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[2], line 17\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m50_samples.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mdate_iso\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m50_samples_cleaned.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     19\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(output, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mTypeError\u001b[0m: date_iso() missing 1 required positional argument: 'df'"
          ]
        }
      ],
      "source": [
        "# new preprocessing with the goal to\n",
        "# remove trailing and leading zeros\n",
        "# yyyy-mm-dd\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "spongeSample_patj = Path.cwd()\n",
        "\n",
        "def date_iso(df):\n",
        "    if 'date' in df.columns:\n",
        "        df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "        return df\n",
        "\n",
        "def main():\n",
        "    csv_path = '50_samples.csv'\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df = date_iso(df)  # <-- assign the modified DataFrame back\n",
        "    output = '50_samples_final.csv'\n",
        "    df.to_csv(output, index=False, quoting=1, encoding='utf-8')\n",
        "\n",
        "        \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned data saved to: c:\\Users\\User\\Desktop\\Sponge-Database\\PGC_Raw_Data_Cleaned.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "sponge_path = Path.cwd()\n",
        "\n",
        "def general_cleaning(df):\n",
        "    df = df.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "    df.columns = [re.sub(r'\\s+', '_', col.strip().lower()) for col in df.columns]\n",
        "    df = df.replace({r'\"': '', r\"'\": '', r'\\\\': ''}, regex=True)\n",
        "    df = df.replace({r'\\r\\n|\\r': '\\n'}, regex=True)\n",
        "    return df\n",
        "\n",
        "def data_consistency(df):\n",
        "    for col in ['dive_no', 'otu']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    if 'date' in df.columns:\n",
        "        df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
        "\n",
        "\n",
        "    df = df.replace({'yes': True, 'no': False, 'Yes': True, 'No': False}, regex=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def date_cleaning(df):\n",
        "    if 'date' in df.columns:\n",
        "        df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "    return df\n",
        "\n",
        "def categorical_normalization(df):\n",
        "    categorical_columns = ['location', 'site', 'sample_code']\n",
        "    for col in categorical_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(str).str.lower().str.replace('/', '-', regex=False)\n",
        "    return df\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def fill_missing_values(df):\n",
        "    # Convert empty strings to NaN\n",
        "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
        "\n",
        "    # Fill string (object) columns with 'unknown'\n",
        "    string_cols = df.select_dtypes(include='object').columns\n",
        "    df[string_cols] = df[string_cols].fillna('unknown')\n",
        "\n",
        "    # For numeric columns, keep NaN as is or fill with sentinel if you want\n",
        "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "    # Here we just keep NaN to show missing numeric data clearly\n",
        "    df[numeric_cols] = df[numeric_cols].where(pd.notnull(df[numeric_cols]), np.nan)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# def fill_unknown_values(df, columns):\n",
        "#     for col in columns:\n",
        "#         if col in df.columns:\n",
        "#             df[col] = df[col].fillna('unknown')\n",
        "#     return df\n",
        "\n",
        "def main():\n",
        "    csv_path = sponge_path / \"PGC_MCE2_Sponge Diversity 2023 - Raw Data.csv\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    df = general_cleaning(df)\n",
        "    df = data_consistency(df)\n",
        "    df = categorical_normalization(df)\n",
        "    df = fill_missing_values(df)\n",
        "    df = date_cleaning(df)\n",
        "    # df = fill_unknown_values(df, ['putative_id', 'barcode_sequences', 'skeletal'])\n",
        "\n",
        "    for col in ['barcode_sequences', 'skeletal']:\n",
        "        if col in df.columns:df[col] = df[col].astype('string').fillna('unknown')\n",
        "\n",
        "    output_path = sponge_path / \"PGC_Raw_Data_Cleaned.csv\"\n",
        "    df.to_csv(output_path, index=False, quoting=1, encoding='utf-8')\n",
        "\n",
        "    print(f\"Cleaned data saved to: {output_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Cleaned data saved to: c:\\Users\\User\\Desktop\\Sponge-Database\\PGC_OTU_Data_Cleaned.csv\n",
            "ðŸ“„ Columns: ['otu_id', 'photo', 'functional_form', 'growth_form', 'color', 'surface_texture', 'oscule_shape', 'oscule_distribution', 'ostia', 'count_no', 'putative_id']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11504\\822125561.py:18: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df[cols_to_clean] = df[cols_to_clean].applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "sponge_path = Path.cwd()\n",
        "\n",
        "def general_cleaning(df):\n",
        "    # Normalize column names (lowercase and underscores)\n",
        "    df.columns = [re.sub(r'\\s+', '_', col.strip().lower()) for col in df.columns]\n",
        "\n",
        "    # Rename functional form column\n",
        "    if 'functional_form_(schonberg,_2021)' in df.columns:\n",
        "        df.rename(columns={'functional_form_(schonberg,_2021)': 'functional_form'}, inplace=True)\n",
        "\n",
        "    # Strip whitespace and remove quotes/backslashes in all except photo\n",
        "    cols_to_clean = [c for c in df.columns if c != 'photo']\n",
        "    df[cols_to_clean] = df[cols_to_clean].applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "    df[cols_to_clean] = df[cols_to_clean].replace({r'\"': '', r\"'\": '', r'\\\\': ''}, regex=True)\n",
        "    df[cols_to_clean] = df[cols_to_clean].replace({r'\\r\\n|\\r': '\\n'}, regex=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def data_consistency(df):\n",
        "    # Convert numeric columns\n",
        "    for col in ['count_no', 'otu_id']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Only convert yes/no in explicitly boolean columns if you have any\n",
        "    # (Avoid replacing 'FALSE' in categorical text)\n",
        "    # If you know which columns are boolean, replace only there.\n",
        "\n",
        "    return df\n",
        "\n",
        "def categorical_normalization(df):\n",
        "    # Lowercase relevant categorical columns and replace '/' with '-'\n",
        "    for col in ['functional_form', 'growth_form', 'color', 'surface_texture', \n",
        "                'oscule_shape', 'oscule_distribution', 'ostia', 'putative_id']:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(str).str.lower().str.replace('/', '-', regex=False)\n",
        "\n",
        "    nan_pattern = r'^\\s*(nan)?\\s*$'\n",
        "\n",
        "    # For surface_texture\n",
        "    if 'surface_texture' in df.columns:\n",
        "        # Replace empty or 'nan' strings with np.nan (case-insensitive)\n",
        "        mask = df['surface_texture'].str.match(nan_pattern, flags=re.IGNORECASE, na=False)\n",
        "        df.loc[mask, 'surface_texture'] = np.nan\n",
        "        df['surface_texture'] = df['surface_texture'].fillna('unknown')\n",
        "\n",
        "    # For putative_id\n",
        "    if 'putative_id' in df.columns:\n",
        "        mask = df['putative_id'].str.match(nan_pattern, flags=re.IGNORECASE, na=False)\n",
        "        df.loc[mask, 'putative_id'] = np.nan\n",
        "        df['putative_id'] = df['putative_id'].fillna('unknown')\n",
        "\n",
        "    return df\n",
        "\n",
        "def fill_missing_values(df):\n",
        "    # Replace empty strings with NaN for all string columns except photo\n",
        "    string_cols = [c for c in df.select_dtypes(include='object').columns if c != 'photo']\n",
        "    df[string_cols] = df[string_cols].replace(r'^\\s*$', np.nan, regex=True)\n",
        "\n",
        "    # Fill missing string values with 'unknown' except photo and surface_texture & putative_id (already handled)\n",
        "    for col in string_cols:\n",
        "        if col not in ['surface_texture', 'putative_id']:\n",
        "            df[col] = df[col].fillna('unknown')\n",
        "\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    csv_path = sponge_path / \"PGC_MCE2_Sponge Diversity 2023 - OTUs.csv\"\n",
        "    output_path = sponge_path / \"PGC_OTU_Data_Cleaned.csv\"\n",
        "\n",
        "    if not csv_path.exists():\n",
        "        print(f\"ERROR: File not found at {csv_path}\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df = general_cleaning(df)\n",
        "    df = data_consistency(df)\n",
        "    df = categorical_normalization(df)\n",
        "    df = fill_missing_values(df)\n",
        "\n",
        "    df.to_csv(output_path, index=False, quoting=1, encoding='utf-8')\n",
        "\n",
        "    print(f\"âœ… Cleaned data saved to: {output_path}\")\n",
        "    print(\"ðŸ“„ Columns:\", df.columns.tolist())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "jupyter_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
